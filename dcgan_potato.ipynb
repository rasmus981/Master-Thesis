{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy import misc\n",
    "import scipy.ndimage\n",
    "from skimage import feature\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Lambda, Input, Conv2DTranspose, Reshape, UpSampling2D, BatchNormalization, Activation, Concatenate\n",
    "from keras.models import model_from_json, Model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from scipy.stats import norm\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_hollow_data(procent, model_number):\n",
    "    train_hollow_folder = \"potato_dataset/data_\" + str(procent) + \"/model_\" + str(model_number) + \"/train/hollow/\"\n",
    "    \n",
    "    train_data_hollow = []\n",
    "    \n",
    "    for filename in os.listdir(train_hollow_folder):\n",
    "        if filename != \".DS_Store\" and filename != \".png\" and filename != \".ipynb_checkpoints\":\n",
    "            img = (cv2.imread(train_hollow_folder + filename, cv2.IMREAD_GRAYSCALE) / 255.0)\n",
    "            train_data_hollow.append(img)\n",
    "            \n",
    "            \n",
    "    np_train_data_hollow = np.array(train_data_hollow)\n",
    "    \n",
    "    train_data = np_train_data_hollow.reshape(np_train_data_hollow.shape[0], 128, 128, 1)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_metal_data(procent, model_number):\n",
    "    train_metal_folder = \"potato_dataset/data_\" + str(procent) + \"/model_\" + str(model_number) + \"/train/metal/\"\n",
    "    \n",
    "    train_data_metal = []\n",
    "    \n",
    "    for filename in os.listdir(train_metal_folder):\n",
    "        if filename != \".DS_Store\" and filename != \".png\" and filename != \".ipynb_checkpoints\":\n",
    "            img = (cv2.imread(train_metal_folder + filename, cv2.IMREAD_GRAYSCALE) / 255.0)\n",
    "            train_data_metal.append(img)\n",
    "            \n",
    "            \n",
    "    np_train_data_metal = np.array(train_data_metal)\n",
    "    \n",
    "    train_data = np_train_data_metal.reshape(np_train_data_metal.shape[0], 128, 128, 1)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_perfect_data(procent, model_number):\n",
    "    train_perfect_folder = \"potato_dataset/data_\" + str(procent) + \"/model_\" + str(model_number) + \"/train/perfect/\"\n",
    "    \n",
    "    train_data_perfect = []\n",
    "    \n",
    "    for filename in os.listdir(train_perfect_folder):\n",
    "        if filename != \".DS_Store\" and filename != \".png\" and filename != \".ipynb_checkpoints\":\n",
    "            img = (cv2.imread(train_perfect_folder + filename, cv2.IMREAD_GRAYSCALE) / 255.0)\n",
    "            train_data_perfect.append(img)\n",
    "            \n",
    "            \n",
    "    np_train_data_perfect = np.array(train_data_perfect)\n",
    "    \n",
    "    train_data = np_train_data_perfect.reshape(np_train_data_perfect.shape[0], 128, 128, 1)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(input_layer, condition_layer, img_shape):\n",
    "    \n",
    "    # Input to Dense\n",
    "    merged_input = Concatenate()([input_layer, condition_layer])\n",
    "    generator = Dense(256, activation='relu')(merged_input)\n",
    "    generator = Dense(16*4*4, activation='relu')(generator)\n",
    "    generator = Reshape((4, 4, 16)) (generator)\n",
    "    generator = LeakyReLU(alpha=0.2) (generator)\n",
    "    \n",
    "    # Conv Layer 0\n",
    "    generator = keras.layers.Conv2DTranspose(filters=16, kernel_size=[3,3], padding=\"same\",\n",
    "                                             strides=[2,2])(generator)\n",
    "    #generator = BatchNormalization(momentum=0.8) (generator)\n",
    "    generator = keras.layers.LeakyReLU(alpha=0.2) (generator)\n",
    "    \n",
    "    # Conv Layer 1\n",
    "    generator = keras.layers.Conv2DTranspose(filters=16, kernel_size=[3,3], padding=\"same\",\n",
    "                                             strides=[2,2])(generator)\n",
    "    generator = BatchNormalization(momentum=0.8) (generator)\n",
    "    generator = keras.layers.LeakyReLU(alpha=0.2) (generator)\n",
    "    \n",
    "    \n",
    "    # Conv Layer 2\n",
    "    generator = keras.layers.Conv2DTranspose(filters=16, kernel_size=[3,3], padding=\"same\", strides=[2,2])(generator)\n",
    "    generator = BatchNormalization(momentum=0.8, name=\"batch_trans_conv2\") (generator)\n",
    "    generator = keras.layers.LeakyReLU(alpha=0.2) (generator)\n",
    "\n",
    "    \n",
    "    # Conv Layer 3\n",
    "    generator = keras.layers.Conv2DTranspose(filters=16, kernel_size=[3,3], padding=\"same\", strides=[2,2])(generator)\n",
    "    generator = BatchNormalization(momentum=0.8,name=\"batch_trans_conv3\") (generator)\n",
    "    generator = keras.layers.LeakyReLU(alpha=0.2)(generator)\n",
    "    \n",
    "    \n",
    "    # Conv Layer 4\n",
    "    generator = keras.layers.Conv2DTranspose(filters=16, kernel_size=[3,3], padding=\"same\", strides=[2,2]) (generator)\n",
    "    generator = BatchNormalization(momentum=0.8,name=\"batch_trans_conv4\") (generator)\n",
    "    generator = keras.layers.LeakyReLU(alpha=0.2) (generator)\n",
    "    \n",
    "    \n",
    "    # Output Conv\n",
    "    generator = keras.layers.Conv2DTranspose(filters=1, kernel_size=[3,3], padding=\"same\", strides=[1,1])(generator)\n",
    "    out = Activation(\"sigmoid\")(generator)\n",
    "    \n",
    "    model = Model(inputs=[input_layer, condition_layer], outputs=out)\n",
    "    #model.summary()\n",
    "  \n",
    "    return model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(input_layer, condition_layer, img_shape):\n",
    "    # Small float added to variance to avoid dividing by zero when batch normalization\n",
    "    EPSILON = 0.00005\n",
    "    \n",
    "    \n",
    "    # Conv Layer 1\n",
    "    discriminator = Conv2D(filters = 16, kernel_size=[3,3],strides=[2,2], padding=\"same\",input_shape = img_shape)(input_layer)\n",
    "    discriminator = BatchNormalization(momentum=0.8)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha=0.2)(discriminator)\n",
    "\n",
    "    \n",
    "    # Conv Layer 2\n",
    "    discriminator = Conv2D(filters=16, kernel_size=[3,3], strides=[2,2], padding=\"same\")(discriminator)\n",
    "    discriminator = BatchNormalization(momentum=0.8)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha=0.2)(discriminator)\n",
    "    \n",
    "    \n",
    "    # Conv Layer 3\n",
    "    discriminator = Conv2D(filters=16, kernel_size=[3,3], strides=[2,2], padding=\"same\")(discriminator)\n",
    "    discriminator = BatchNormalization(momentum=0.8)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha=0.2)(discriminator)\n",
    "    \n",
    "    \n",
    "    # Conv Layer 4\n",
    "    discriminator = Conv2D(filters=16, kernel_size=[3,3], strides=[2,2], padding=\"same\")(discriminator)\n",
    "    discriminator = BatchNormalization(momentum=0.8,epsilon = EPSILON)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha=0.2)(discriminator)\n",
    "\n",
    "    # Conv Layer 5\n",
    "    discriminator = Conv2D(filters=16, kernel_size=[5,5], strides=[1,1], padding=\"same\")(discriminator)\n",
    "    discriminator = BatchNormalization(momentum=0.8,epsilon = EPSILON)(discriminator)\n",
    "    discriminator = LeakyReLU(alpha=0.2)(discriminator)\n",
    "\n",
    "    # Output layer\n",
    "    discriminator = Flatten()(discriminator)\n",
    "    merged_layer = Concatenate()([discriminator, condition_layer])\n",
    "    out = Dense(1, activation='sigmoid')(merged_layer)\n",
    "\n",
    "    model = Model(inputs=[input_layer, condition_layer], outputs=out)\n",
    "    #model.summary()\n",
    "    \n",
    "    return model,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(sample_images, name, epoch):\n",
    "    figure, axes = plt.subplots(1, len(sample_images), figsize = (128, 128))\n",
    "    figure.set_size_inches(15,15)\n",
    "    for index, axis in enumerate(axes):\n",
    "        #print(index, axis)\n",
    "        image_array = sample_images[index]\n",
    "        image_array = np.array(image_array).reshape(128, 128)\n",
    "        axis.imshow(image_array)\n",
    "    plt.savefig(name+\"_\"+str(epoch)+\".png\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def summarize_epoch(d_losses, g_losses):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
    "    plt.plot(g_losses, label='Generator', alpha=0.6)\n",
    "    plt.title(\"Losses\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def get_batches(data, batch_size):\n",
    "    batches = []\n",
    "    for i in range(int(data.shape[0]//batch_size)):\n",
    "        batch = data[i * batch_size:(i + 1) * batch_size]\n",
    "        batches.append(batch)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, latent_dim):\n",
    "    z = np.zeros((len(y), latent_dim))\n",
    "    idx = np.arange(len(y))\n",
    "    z[idx, y] = 1\n",
    "    return z\n",
    "\n",
    "def generate_noise(n_samples, noise_size):\n",
    "    X = np.random.normal(0, 1, size=(n_samples, noise_size))\n",
    "    return X\n",
    "\n",
    "def generate_random_labels(n, batch_size, latent_dim):\n",
    "    y = np.random.choice(batch_size, n)\n",
    "    y = one_hot_encode(y, latent_dim)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(input_images, procent, model, potato_type, number_of_images, batch_size, epochs, start_to_save):\n",
    "    # Hyperparameters\n",
    "    image_size = 128\n",
    "    image_shape = (128, 128, 1)\n",
    "    latent_dim = 50\n",
    "    lr_discriminator = 0.004\n",
    "    lr_generator = 0.004\n",
    "    batch_size = input_images.shape[0]\n",
    "    weight_init_stddev = 0.02\n",
    "    epochs = epochs\n",
    "    eps = 0.00005\n",
    "    beta1 = 0.5\n",
    "    samples_to_show = 5\n",
    "    data_path = \"potato_dataset/data_\" + str(procent) + \"/model_\" + str(model) + \"/gan_3/\" + potato_type + \"/\"\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # GAN creation\n",
    "    img_input = Input(shape=image_shape)\n",
    "    disc_condition_input = Input(shape=(10,))\n",
    "\n",
    "    #Build the Discriminator\n",
    "    discriminator, disc_out = create_discriminator(img_input, disc_condition_input, image_shape)\n",
    "    discriminator.compile(optimizer=Adam(lr=lr_discriminator, beta_1=beta1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    #Build the Generator\n",
    "    noise_input = Input(shape=(latent_dim,))\n",
    "    gen_condition_input = Input(shape=(10,))\n",
    "    generator, gen_out = create_generator(noise_input, gen_condition_input, image_shape)\n",
    "\n",
    "    #Build GAN\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    gan_process = generator([gan_input, gen_condition_input])\n",
    "    gan_output = discriminator([gan_process, disc_condition_input])\n",
    "    gan = Model(inputs=[gan_input, gen_condition_input, disc_condition_input], outputs=gan_output)\n",
    "    #gan.summary()\n",
    "\n",
    "    gan.compile(optimizer=Adam(lr=lr_generator, beta_1=beta1), loss='binary_crossentropy')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    input_images = np.asarray(input_images)\n",
    "    np.random.shuffle(input_images)\n",
    "    \n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    exp_replay = []\n",
    "    batch_count = len(input_images)\n",
    "    image_number = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        cum_d_loss = 0.\n",
    "        cum_g_loss = 0.\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx in range(1):\n",
    "            # Get the next set of real images to be used in this iteration\n",
    "            images = input_images[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "            labels = np.zeros((batch_size,10))\n",
    "\n",
    "            noise_data = generate_noise(batch_size, latent_dim)\n",
    "            random_labels = generate_random_labels(batch_size, batch_size, latent_dim)\n",
    "            # We use same labels for generated images as in the real training batch\n",
    "            generated_images = generator.predict([noise_data, labels])\n",
    "\n",
    "            # Train on soft targets (add noise to targets as well)\n",
    "            noise_prop = 0.05 # Randomly flip 5% of targets\n",
    "\n",
    "            # Prepare labels for real data\n",
    "            true_labels = np.zeros((batch_size, 1)) + np.random.uniform(low=0.0, high=0.1, size=(batch_size, 1))\n",
    "            flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n",
    "            true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n",
    "\n",
    "            # Train discriminator on real data\n",
    "            discriminator.trainable = True\n",
    "            d_loss_true = discriminator.train_on_batch([images, labels], true_labels)\n",
    "\n",
    "            # Prepare labels for generated data\n",
    "            gene_labels = np.ones((batch_size, 1)) - np.random.uniform(low=0.0, high=0.1, size=(batch_size, 1))\n",
    "            flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n",
    "            gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n",
    "\n",
    "            # Train discriminator on generated data\n",
    "            d_loss_gene = discriminator.train_on_batch([generated_images, labels], gene_labels)\n",
    "\n",
    "            # Store a random point for experience replay\n",
    "            r_idx = np.random.randint(batch_size)\n",
    "            exp_replay.append([generated_images[r_idx], labels[r_idx], gene_labels[r_idx]])\n",
    "\n",
    "            #If we have enough points, do experience replay\n",
    "            if len(exp_replay) == batch_size:\n",
    "                generated_images = np.array([p[0] for p in exp_replay])\n",
    "                labels = np.array([p[1] for p in exp_replay])\n",
    "                gene_labels = np.array([p[2] for p in exp_replay])\n",
    "                expprep_loss_gene = discriminator.train_on_batch([generated_images, labels], gene_labels)\n",
    "                exp_replay = []\n",
    "                break\n",
    "\n",
    "            d_loss = 0.5 * np.add(d_loss_true, d_loss_gene)\n",
    "            cum_d_loss += d_loss[0]\n",
    "            d_losses.append(d_loss[0])\n",
    "\n",
    "            # Train generator\n",
    "            noise_data = generate_noise(batch_size, latent_dim)\n",
    "            random_labels = np.zeros((batch_size,10))\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch([noise_data, random_labels, random_labels], np.zeros((batch_size, 1)))\n",
    "            cum_g_loss += g_loss\n",
    "            g_losses.append(g_loss)\n",
    "\n",
    "        # Uncomment if you want visulazation of Images\n",
    "        '''\n",
    "        if epoch % 200 == 0:\n",
    "            summarize_epoch(d_losses, g_losses)\n",
    "            #print(batch_count)\n",
    "            print('\\tEpoch: {}, Generator Loss: {}, Discriminator Loss: {}, Time: {}'.format(epoch+1, cum_g_loss/batch_count,\n",
    "                                                                             cum_d_loss/batch_count, time.time()-start_time))\n",
    "            samples = generator.predict([noise_data[:samples_to_show], np.ones((samples_to_show,10))])\n",
    "            sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples]\n",
    "            show_samples(sample_images, OUTPUT_DIR + \"samples\", 0)\n",
    "        '''\n",
    "        if(epoch >= start_to_save) and (epoch % 200 == 0):\n",
    "            noise_data = generate_noise(number_of_images, latent_dim)\n",
    "            labels = np.zeros((number_of_images,10))\n",
    "            # We use same labels for generated images as in the real training batch\n",
    "            generated_images = generator.predict([noise_data, labels])\n",
    "            for noise_img in generated_images:\n",
    "                plt.imsave(data_path + potato_type +\"_gan_\" + str(image_number) + \".jpg\", noise_img.reshape(128, 128))\n",
    "                image_number += 1\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(10, 100, 10):\n",
    "    start1 = time.time()\n",
    "    for j in range(1, 11):\n",
    "        start2 = time.time()\n",
    "        hollow_data = get_train_hollow_data(p, j)\n",
    "        run_model(hollow_data, p, j, \"hollow\", 10 + int(p / 10), hollow_data[0], 1600 + (p * 10) , 600 + (p * 10))\n",
    "        end2 = time.time()\n",
    "        print(\"Hollow Model {} with {} procent of the data took {} second\".format(j, p, end2 - start2))\n",
    "        \n",
    "        start2 = time.time()\n",
    "        metal_data = get_train_metal_data(p, j)\n",
    "        run_model(metal_data, p, j, \"metal\", 10 + int(p / 10), metal_data[0], 1600 + (p * 10) , 600 + (p * 10))\n",
    "        end2 = time.time()\n",
    "        print(\"metal Model {} with {} procent of the data took {} second\".format(j, p, end2 - start2))\n",
    "        \n",
    "        start2 = time.time()\n",
    "        perfect_data = get_train_perfect_data(p, j)\n",
    "        run_model(perfect_data, p, j, \"perfect\", 10 + int(p / 10), perfect_data[0], 1600 + (p * 10) , 600 + (p * 10))\n",
    "        end2 = time.time()\n",
    "        print(\"perfect Model {} with {} procent of the data took {} second\".format(j, p, end2 - start2))\n",
    "\n",
    "    end1 = time.time()\n",
    "    print(\"VAE for {} procent of data took {} second\".format(p, end1 - start1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
