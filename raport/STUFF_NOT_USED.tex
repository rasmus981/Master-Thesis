


% Introduction stuff start



\subsection{STUFF NOT USED}
The best way to make a machine learning model generalize well is to train it on a lot of data, but in practice the amount of data available is often limited. The purpose of this thesis is to investigate if it's possible to create fake data using data augmentation techniques to improve the machine learning model. To gain an understanding of the topics discussed in this thesis it is recommended that the reader has a basic understanding of calculus and probability theory. 

When training a \texttt{machine learning model} we need three things, a \texttt{learning algorithm} for the task we want to solve, computing power and data. One of the main reasons that a machine learning model don't performs as great as expected is due to lack of data. When training a machine learning model with a to small dataset often influence the performance in a negative way, and the final model have a bigger risk of \texttt{overfitting}. 
 
In supervised learning problems 




For most machine learning models one of the biggest issues is the lack of labelled data. The
limited amount of training data can influence the performance of supervised machine
learning algorithms and with few training examples the risk of overfitting the model is
increased.
In this master thesis I will look into how to produce labelled data, which can be used for
training machine learning models.
The main focus of this thesis will be on using deep generative models to generate data, for
improving the accuracy for machine learning models.
The second focus in this master thesis will be on object detection using deep learning. The
HPC group at KU are currently involved in a large project about X-ray scanning images of
highly homogeneous food items and then detecting and classify these food items. So overall
I will try to generate training data for the X-ray scanning project at KU, using deep generative
models, with focus on improving the accuracy of object detection models.

% Introduction stuff end